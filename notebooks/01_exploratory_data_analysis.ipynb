{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Práctico - Científico de Datos SICEX\n",
    "## Desafío: Unificación y Normalización de Entidades\n",
    "\n",
    "\n",
    "### Instrucciones\n",
    "\n",
    "Bienvenido al test práctico para el puesto de Científico de Datos en SICEX.\n",
    "\n",
    "### CONTEXTO:\n",
    "SICEX maneja grandes volúmenes de datos de comercio exterior donde uno de los principales \n",
    "desafíos es la consistencia y normalización de entidades como nombres de empresas,\n",
    "ciudades y productos. Este test evaluará tu capacidad para proponer e implementar\n",
    "soluciones a este problema real.\n",
    "\n",
    "### OBJETIVOS DE EVALUACIÓN:\n",
    "- Capacidad de análisis y limpieza de datos\n",
    "- Habilidad para desarrollar algoritmos de matching y normalización\n",
    "- Pensamiento creativo en la resolución de problemas\n",
    "- Capacidad de escalar soluciones\n",
    "- Documentación y comunicación técnica\n",
    "\n",
    "Tiempo estimado: 2 horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from etl_data_science_test import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar datos\n",
    "def load_and_examine_data():\n",
    "    # Cargar el dataset\n",
    "    filepath = os.path.join(config.RAW_DATA_DIR, '10_Importaciones_2024_Octubre.xlsx')\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # Información básica del dataset\n",
    "    print(\"=== INFORMACIÓN BÁSICA DEL DATASET ===\")\n",
    "    print(f\"Número de registros: {len(df)}\")\n",
    "    print(f\"Número de columnas: {len(df.columns)}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EJERCICIO 1: ANÁLISIS EXPLORATORIO Y DIAGNÓSTICO \n",
    "\n",
    "Trabajaremos con un dataset real de importaciones que contiene información sobre empresas\n",
    "y ubicaciones. Tu primera tarea es realizar un análisis exploratorio enfocado en \n",
    "la calidad de los datos de las entidades.\n",
    "\n",
    "### Analiza específicamente:\n",
    "1. Nombres de empresas (NOMBRE_IMPORTADOR, NOMBRE_EXPORTADOR)\n",
    "2. Ubicaciones (CIUDAD_PAIS_EXPORTADOR, DEPARTAMENTO_IMPORTADOR)\n",
    "3. Direcciones (DIRECCION_IMPORTADOR, DIRECCION_EXPORTADOR)\n",
    "\n",
    "### Para cada campo:\n",
    "- Identifica patrones en las inconsistencias\n",
    "- Cuantifica el impacto de estas inconsistencias\n",
    "- Propón una estrategia de limpieza y normalización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_entity_fields(df):\n",
    "  # Tu código aquí\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Análisis de patrones y anomalías\n",
    "def analyze_patterns(df):\n",
    "    print(\"\\n=== ANÁLISIS DE PATRONES Y ANOMALÍAS ===\")\n",
    "    # Tu código aquí\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generar visualizaciones\n",
    "def create_visualizations(df, entity_stats):\n",
    "    # Configuración de estilo\n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    # 1. Gráfico de completitud de datos\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # Tu código aquí\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_examine_data()\n",
    "    \n",
    "# 2. Analizar campos de entidades\n",
    "entity_stats = analyze_entity_fields(df)\n",
    "\n",
    "# 3. Analizar patrones\n",
    "patterns = analyze_patterns(df)\n",
    "\n",
    "# 4. Crear visualizaciones\n",
    "create_visualizations(df, entity_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2: DESARROLLO DE ALGORITMO DE MATCHING\n",
    "\n",
    "\n",
    "Desarrolla un algoritmo que pueda identificar cuando dos nombres de empresa se refieren\n",
    "a la misma entidad, considerando:\n",
    "- Variaciones en el orden de las palabras\n",
    "- Errores tipográficos comunes\n",
    "- Abreviaciones y acrónimos\n",
    "- Diferentes formatos legales (S.A., LTDA, etc.)\n",
    "\n",
    "Requerimientos:\n",
    "1. Implementa al menos dos métodos diferentes de matching\n",
    "2. Evalúa y compara su efectividad\n",
    "3. Propón una métrica para medir la calidad del matching\n",
    "4. Documenta los casos edge que identificaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_company_name(name):\n",
    "    \"\"\"\n",
    "    Implementa la normalización básica de nombres de empresas.\n",
    "    \"\"\"\n",
    "    # Tu código aquí\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_companies(name1, name2, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Implementa el algoritmo de matching entre dos nombres de empresa.\n",
    "    \"\"\"\n",
    "    # Tu código aquí\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba tu implementación con algunos casos de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3: ESCALABILIDAD Y OPTIMIZACIÓN\n",
    "\n",
    "Ahora que has desarrollado un algoritmo básico, necesitamos escalarlo para procesar\n",
    "grandes volúmenes de datos eficientemente.\n",
    "\n",
    "### Tareas:\n",
    "1. Optimiza tu algoritmo para mejorar su rendimiento\n",
    "2. Implementa una estrategia para reducir comparaciones innecesarias\n",
    "3. Propón una estructura de datos eficiente para almacenar los matches\n",
    "4. Sugiere una arquitectura para procesar actualizaciones incrementales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO BONUS: INTEGRACIÓN CON LLMs\n",
    "\n",
    "Demuestra cómo podrías mejorar la solución anterior utilizando Large Language Models (LLMs).\n",
    "Específicamente, integra Groq (https://groq.com/) y otros modelos open source como Llama.\n",
    "\n",
    "#### Objetivos:\n",
    "1. Uso de LLMs para mejorar el matching y normalización\n",
    "2. Implementación eficiente y costos-efectiva\n",
    "3. Manejo de casos edge con ayuda de LLMs\n",
    "\n",
    "##### Tareas:\n",
    "1. Implementa un pipeline que utilice Groq API para:\n",
    "   - Normalización de nombres de empresas\n",
    "   - Detección de entidades similares\n",
    "   - Validación de matches dudosos\n",
    "\n",
    "2. Compara el rendimiento y precisión entre:\n",
    "   - Tu solución basada en reglas/algoritmos\n",
    "   - Solución utilizando LLMs\n",
    "   - Enfoque híbrido\n",
    "\n",
    "3. Optimización de costos:\n",
    "   - Estrategia para minimizar llamadas a la API\n",
    "   - Caching inteligente de resultados\n",
    "   - Balance entre precisión y costos\n",
    "\n",
    "4. Casos de uso avanzados:\n",
    "   - Extracción de información adicional de las descripciones\n",
    "   - Categorización automática de empresas\n",
    "   - Detección de anomalías en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_entity_with_llm(entity_name, client):\n",
    "    \"\"\"\n",
    "    Utiliza Groq para normalizar nombres de entidades\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Normaliza el siguiente nombre de empresa, eliminando variaciones innecesarias \n",
    "    y manteniendo la información esencial: {entity_name}\n",
    "    \n",
    "    Formato deseado:\n",
    "    - Sin puntuación innecesaria\n",
    "    - Siglas de forma estándar\n",
    "    - Tipo de empresa al final (SA, LTDA, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"mixtral-8x7b-32768\",  # o cualquier otro modelo disponible en Groq\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Eres un experto en normalización de nombres de empresas.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al llamar a Groq API: {e}\")\n",
    "        return entity_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_entities_with_llm(entity1, entity2, client):\n",
    "    \"\"\"\n",
    "    Utiliza Groq para determinar si dos entidades son la misma\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Determina si las siguientes dos empresas son la misma entidad:\n",
    "    Empresa 1: {entity1}\n",
    "    Empresa 2: {entity2}\n",
    "    \n",
    "    Responde con:\n",
    "    - MATCH: Si son definitivamente la misma empresa\n",
    "    - POSSIBLE_MATCH: Si probablemente son la misma empresa\n",
    "    - NO_MATCH: Si son empresas diferentes\n",
    "    \n",
    "    Explica tu razonamiento.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Eres un experto en identificación y matching de entidades empresariales.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al llamar a Groq API: {e}\")\n",
    "        return \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementa tu solución utilizando estas funciones como base\n",
    "# Demuestra cómo integrarías esto en tu pipeline general de matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl-data-science-test-tnNkhD88",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
